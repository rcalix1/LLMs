{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fecb033",
   "metadata": {},
   "source": [
    "## Warm Starting BERT 2 GPT2\n",
    "\n",
    "Bert2GPT2 is a EncoderDecoderModel, meaning that \n",
    "\n",
    "* the encoder -->> bert-base-uncased BERT model\n",
    "* the decoder -->> GPT2 model. \n",
    "\n",
    "Leveraging the EncoderDecoderFramework, the two pretrained models can simply be loaded into the framework.\n",
    "\n",
    "The decoder of an EncoderDecoder model needs cross-attention layers and usually makes use of causal masking for auto-regressiv generation. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91bbdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e93bafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import transformers\n",
    "import numpy\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import nlp\n",
    "import logging\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from datasets import ClassLabel\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import BertTokenizer, GPT2Tokenizer\n",
    "from transformers import EncoderDecoderModel, Trainer, TrainingArguments\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1adcd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_length = 512\n",
    "decoder_length = 128\n",
    "batch_size     = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8731a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b11b1e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.6.crossattention.c_proj.bias', 'h.8.crossattention.masked_bias', 'h.11.crossattention.bias', 'h.10.crossattention.c_proj.bias', 'h.4.crossattention.bias', 'h.7.crossattention.q_attn.weight', 'h.5.crossattention.bias', 'h.4.ln_cross_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.2.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.9.ln_cross_attn.weight', 'h.0.crossattention.bias', 'h.11.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.11.crossattention.q_attn.weight', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.2.crossattention.c_attn.weight', 'h.7.crossattention.bias', 'h.8.crossattention.bias', 'h.10.crossattention.c_proj.weight', 'h.5.crossattention.masked_bias', 'h.6.crossattention.c_attn.weight', 'h.7.crossattention.c_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.1.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.weight', 'h.7.crossattention.masked_bias', 'h.10.crossattention.bias', 'h.11.crossattention.c_proj.weight', 'h.11.ln_cross_attn.weight', 'h.9.crossattention.masked_bias', 'h.9.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.weight', 'h.1.crossattention.bias', 'h.4.crossattention.c_proj.weight', 'h.2.crossattention.masked_bias', 'h.4.crossattention.q_attn.weight', 'h.9.crossattention.bias', 'h.1.crossattention.c_attn.weight', 'h.1.ln_cross_attn.weight', 'h.6.crossattention.masked_bias', 'h.10.crossattention.c_attn.weight', 'h.8.crossattention.c_attn.weight', 'h.6.ln_cross_attn.weight', 'h.3.ln_cross_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.11.crossattention.masked_bias', 'h.5.crossattention.c_proj.weight', 'h.11.crossattention.c_proj.bias', 'h.1.crossattention.q_attn.weight', 'h.6.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.5.crossattention.q_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.6.crossattention.bias', 'h.3.crossattention.masked_bias', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_attn.weight', 'h.5.ln_cross_attn.weight', 'h.10.ln_cross_attn.weight', 'h.3.crossattention.bias', 'h.0.crossattention.masked_bias', 'h.0.ln_cross_attn.weight', 'h.0.crossattention.q_attn.weight', 'h.8.crossattention.c_proj.weight', 'h.8.ln_cross_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.10.crossattention.masked_bias', 'h.4.crossattention.masked_bias', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.weight', 'h.2.crossattention.bias', 'h.1.crossattention.masked_bias', 'h.7.ln_cross_attn.weight', 'h.3.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model     = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-cased\", \"gpt2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "819ece8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cache is currently not supported by EncoderDecoder framework\n",
    "\n",
    "model.decoder.config.use_cache = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd301d",
   "metadata": {},
   "source": [
    "* CLS token will work as BOS token\n",
    "* SEP token will work as EOS token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96c45e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "bert_tokenizer.bos_token = bert_tokenizer.cls_token\n",
    "bert_tokenizer.eos_token = bert_tokenizer.sep_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81cc77",
   "metadata": {},
   "source": [
    "\n",
    "## Make sure GPT2 appends EOS in begin and end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "931e9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04297ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GPT2Tokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens\n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e94feb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set pad_token_id to unk_token_id -> be careful here as unk_token_id == eos_token_id == bos_token_id\n",
    "\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.unk_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9edbb",
   "metadata": {},
   "source": [
    "\n",
    "## Set decoding params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "099d7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.config.decoder_start_token_id = gpt2_tokenizer.bos_token_id\n",
    "model.config.eos_token_id           = gpt2_tokenizer.eos_token_id\n",
    "model.config.max_length             = 142\n",
    "model.config.min_length             = 56\n",
    "model.config.no_repeat_ngram_size   = 3\n",
    "model.early_stopping                = True\n",
    "model.length_penalty                = 2.0\n",
    "model.num_beams                     = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678420ad",
   "metadata": {},
   "source": [
    "\n",
    "## Load train and validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be749ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/Users/user/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
      "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/Users/user/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_dataset = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "val_dataset   = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation[:5%]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fa75ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNN/DailyMail non-anonymized summarization dataset.\\n\\nThere are two features:\\n  - article: text of news article, used as the document to be summarized\\n  - highlights: joined text of highlights with <s> and </s> around each\\n    highlight, which is the target summary\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.info.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da5be969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don't think I'll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he'll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I'll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe's earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say 'kid star goes off the rails,'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter's latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer's \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he's legally an adult: \"I just think I'm going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won't do what they're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they're in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the 'forgotten floor' » . At first, it's hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that's kind of what they look like. They're designed to keep the mentally ill patients from injuring themselves. That's also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it's not supposed to be warm and comforting, but the lights glare, the cells are tiny and it's loud. We see two, sometimes three men -- sometimes in the robes, sometimes naked, lying or sitting in their cells. \"I am the son of the president. You need to get me out of here!\" one man shouts at me. He is absolutely serious, convinced that help is on the way -- if only he could reach the White House. Leifman tells me that these prisoner-patients will often circulate through the system, occasionally stabilizing in a mental hospital, only to return to jail to face their charges. It's brutally unjust, in his mind, and he has become a strong advocate for changing things in Miami. Over a meal later, we talk about how things got this way for mental patients. Leifman says 200 years ago people were considered \"lunatics\" and they were locked up in jails even if they had no charges against them. They were just considered unfit to be in society. Over the years, he says, there was some public outcry, and the mentally ill were moved out of jails and into hospitals. But Leifman says many of these mental hospitals were so horrible they were shut down. Where did the patients go? Nowhere. The streets. They became, in many cases, the homeless, he says. They never got treatment. Leifman says in 1955 there were more than half a million people in state mental hospitals, and today that number has been reduced 90 percent, and 40,000 to 50,000 people are in mental hospitals. The judge says he's working to change this. Starting in 2008, many inmates who would otherwise have been brought to the \"forgotten floor\"  will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment, not just punishment. Leifman says it's not the complete answer, but it's a start. Leifman says the best part is that it's a win-win solution. The patients win, the families are relieved, and the state saves money by simply not cycling these prisoners through again and again. And, for Leifman, justice is served. E-mail to a friend .</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on the \"forgotten floor\"\\nJudge Steven Leifman says most are there as a result of \"avoidable felonies\"\\nWhile CNN tours facility, patient shouts: \"I am the son of the president\"\\nLeifman says the system is unjust and he's fighting for change .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who were on the Minneapolis bridge when it collapsed told harrowing tales of survival. \"The whole bridge from one side of the Mississippi to the other just completely gave way, fell all the way down,\" survivor Gary Babineau told CNN. \"I probably had a 30-, 35-foot free fall. And there's cars in the water, there's cars on fire. The whole bridge is down.\" He said his back was injured but he determined he could move around. \"I realized there was a school bus right next to me, and me and a couple of other guys went over and started lifting the kids off the bridge. They were yelling, screaming, bleeding. I think there were some broken bones.\"  Watch a driver describe his narrow escape » . At home when he heard about the disaster, Dr. John Hink, an emergency room physician, jumped into his car and rushed to the scene in 15 minutes. He arrived at the south side of the bridge, stood on the riverbank and saw dozens of people lying dazed on an expansive deck. They were in the middle of the Mississippi River, which was churning fast, and he had no way of getting to them. He went to the north side, where there was easier access to people. Ambulances were also having a hard time driving down to the river to get closer to the scene. Working feverishly, volunteers, EMTs and other officials managed to get 55 people into ambulances in less than two hours. Occasionally, a pickup truck with a medic inside would drive to get an injured person and bring him back up even ground, Hink told CNN. The rescue effort was controlled and organized, he said; the opposite of the lightning-quick collapse. \"I could see the whole bridge as it was going down, as it was falling,\" Babineau said. \"It just gave a rumble real quick, and it all just gave way, and it just fell completely, all the way to the ground. And there was dust everywhere and it was just like everyone has been saying: It was just like out of the movies.\" Babineau said the rear of his pickup truck was dangling over the edge of a broken-off section of the bridge. He said several vehicles slid past him into the water. \"I stayed in my car for one or two seconds. I saw a couple cars fall,\" he said. \"So I stayed in my car until the cars quit falling for a second, then I got out real quick, ran in front of my truck -- because behind my truck was just a hole -- and I helped a woman off of the bridge with me. \"I just wanted off the bridge, and then I ran over to the school bus. I started grabbing kids and handing them down. It was just complete chaos.\" He said most of the children were crying or screaming. He and other rescuers set them on the ground and told them to run to the river bank, but a few needed to be carried because of their injuries.  See rescuers clamber over rubble » . Babineau said he had no rescue training. \"I just knew what I had to do at the moment.\" Melissa Hughes, 32, of Minneapolis, told The Associated Press that she was driving home when the western edge of the bridge collapsed under her. \"You know that free-fall feeling? I felt that twice,\" Hughes said. A pickup landed on top of her car, but she was not hurt. \"I had no idea there was a vehicle on my car,\" she told AP. \"It's really very surreal.\" Babineau told the Minneapolis Star-Tribune: \"On the way down, I thought I was dead. I literally thought I was dead. \"My truck was completely face down, pointed toward the ground, and my truck got ripped in half. It was folded in half, and I can't believe I'm alive.\"  See and hear eyewitness accounts » . Bernie Toivonen told CNN's \"American Morning\" that his vehicle was on a part of the bridge that ended up tilted at a 45-degree angle. \"I knew the deck was going down, there was no question about it, and I thought I was going to die,\" he said. After the bridge settled and his car remained upright, \"I just put in park, turned the key off and said, 'Oh, I'm alive,' \" he said. E-mail to a friend .</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver says .\\nMan says pickup truck was folded in half; he just has cut on face .\\nDriver: \"I probably had a 30-, 35-foot free fall\"\\nMinnesota bridge collapsed during rush hour Wednesday .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(   train_dataset[:3]      )\n",
    "\n",
    "del df[\"id\"]\n",
    "\n",
    "for column, typ in train_dataset.features.items():\n",
    "      if isinstance(typ, ClassLabel):\n",
    "          df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        \n",
    "display(HTML(df.to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f72edabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id'],\n",
       "    num_rows: 287113\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c814556e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n>>> from nlp import load_dataset\\n>>> datasets = load_dataset('squad')\\n>>> print(datasets)\\n{'train': Dataset(schema: {'id': 'string', 'title': 'string', 'context': 'string', 'question': 'string', 'answers': 'struct<text: list<item: string>, answer_start: list<item: int32>>'}, num_rows: 87599),\\n 'validation': Dataset(schema: {'id': 'string', 'title': 'string', 'context': 'string', 'question': 'string', 'answers': 'struct<text: list<item: string>, answer_start: list<item: int32>>'}, num_rows: 10570)\\n}\\n\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    ">>> from nlp import load_dataset\n",
    ">>> datasets = load_dataset('squad')\n",
    ">>> print(datasets)\n",
    "{'train': Dataset(schema: {'id': 'string', 'title': 'string', 'context': 'string', 'question': 'string', 'answers': 'struct<text: list<item: string>, answer_start: list<item: int32>>'}, num_rows: 87599),\n",
    " 'validation': Dataset(schema: {'id': 'string', 'title': 'string', 'context': 'string', 'question': 'string', 'answers': 'struct<text: list<item: string>, answer_start: list<item: int32>>'}, num_rows: 10570)\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b5544f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nhttps://huggingface.co/docs/datasets/v0.4.0/loading_datasets.html\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "\n",
    "https://huggingface.co/docs/datasets/v0.4.0/loading_datasets.html\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26601b44",
   "metadata": {},
   "source": [
    "## ROGUE metric \n",
    "\n",
    "Load rouge for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784767c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rouge = nlp.load_metric(\"rouge\", experiment_id=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0462bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = gpt2_tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = gpt2_tokenizer.eos_token_id\n",
    "    label_str = gpt2_tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b026a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## map data correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5da1a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def map_to_encoder_decoder_inputs(batch):    # Tokenizer will automatically set [BOS] <text> [EOS] \n",
    "    # use bert tokenizer here for encoder\n",
    "    inputs = bert_tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=encoder_length)\n",
    "    # force summarization <= 128\n",
    "    outputs = gpt2_tokenizer(batch[\"highlights\"], padding=\"max_length\", truncation=True, max_length=decoder_length)\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "\n",
    "    # complicated list comprehension here because pad_token_id alone is not good enough to know whether label should be excluded or not\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if mask == 0 else token for mask, token in mask_and_tokens] for mask_and_tokens in [zip(masks, labels) for masks, labels in zip(batch[\"decoder_attention_mask\"], batch[\"labels\"])]\n",
    "    ]\n",
    "\n",
    "    assert all([len(x) == encoder_length for x in inputs.input_ids])\n",
    "    assert all([len(x) == decoder_length for x in outputs.input_ids])\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0fde1",
   "metadata": {},
   "source": [
    "## Make train dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"article\", \"highlights\"],\n",
    ")\n",
    "\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", \n",
    "    columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bb3fb",
   "metadata": {},
   "source": [
    "\n",
    "## Same for validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896eca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    map_to_encoder_decoder_inputs, batched=True, batch_size=batch_size, remove_columns=[\"article\", \"highlights\"],\n",
    ")\n",
    "\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7894fce",
   "metadata": {},
   "source": [
    "\n",
    "## Set training arguments \n",
    "\n",
    "These params are not really tuned, feel free to change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                     = \"./\",\n",
    "    per_device_train_batch_size    = batch_size,\n",
    "    per_device_eval_batch_size     = batch_size,\n",
    "    predict_from_generate          = True,\n",
    "    evaluate_during_training       = True,\n",
    "    do_train                       = True,\n",
    "    do_eval                        = True,\n",
    "    logging_steps                  = 1000,\n",
    "    save_steps                     = 1000,\n",
    "    eval_steps                     = 1000,\n",
    "    overwrite_output_dir           = True,\n",
    "    warmup_steps                   = 2000,\n",
    "    save_total_limit               = 10,\n",
    "    fp16                           = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef794d",
   "metadata": {},
   "source": [
    "\n",
    "## Instantiate trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model             = model,\n",
    "    args              = training_args,\n",
    "    compute_metrics   = compute_metrics,\n",
    "    train_dataset     = train_dataset,\n",
    "    eval_dataset      = val_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe47aab",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ba287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715a236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d3e1c0",
   "metadata": {},
   "source": [
    "## Fully pre-trained bert2gpt2\n",
    "\n",
    "There is also a pre-trained bert2gpt2 named bert2gpt2-cnn_dailymail-fp16.\n",
    "\n",
    "reuse tokenizer from bert2bert encoder-decoder model\n",
    "\n",
    "Code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b63de78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model    = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2gpt2-cnn_dailymail-fp16\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"patrickvonplaten/bert2bert-cnn_dailymail-fp16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c42b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "article = \"\"\"(CNN)Sigma Alpha Epsilon is under fire for a video showing party-bound fraternity members singing a racist chant. SAE's national chapter suspended the students, but University of Oklahoma President David B\n",
    "oren took it a step further, saying the university's affiliation with the fraternity is permanently done. The news is shocking, but it's not the first time SAE has faced controversy. SAE was founded March 9, 185\n",
    "6, at the University of Alabama, five years before the American Civil War, according to the fraternity website. When the war began, the group had fewer than 400 members, of which \"369 went to war for the Confede\n",
    "rate States and seven for the Union Army,\" the website says. The fraternity now boasts more than 200,000 living alumni, along with about 15,000 undergraduates populating 219 chapters and 20 \"colonies\" seeking fu\n",
    "ll membership at universities. SAE has had to work hard to change recently after a string of member deaths, many blamed on the hazing of new recruits, SAE national President Bradley Cohen wrote in a message on t\n",
    "he fraternity's website. The fraternity's website lists more than 130 chapters cited or suspended for \"health and safety incidents\" since 2010. At least 30 of the incidents involved hazing, and dozens more invol\n",
    "ved alcohol. However, the list is missing numerous incidents from recent months. Among them, according to various media outlets: Yale University banned the SAEs from campus activities last month after members al\n",
    "legedly tried to interfere with a sexual misconduct investigation connected to an initiation rite. Stanford University in December suspended SAE housing privileges after finding sorority members attending a frat\n",
    "ernity function were subjected to graphic sexual content. And Johns Hopkins University in November suspended the fraternity for underage drinking. \"The media has labeled us as the 'nation's deadliest fraternity,\n",
    "' \" Cohen said. In 2011, for example, a student died while being coerced into excessive alcohol consumption, according to a lawsuit. SAE's previous insurer dumped the fraternity. \"As a result, we are paying Lloy\n",
    "d's of London the highest insurance rates in the Greek-letter world,\" Cohen said. Universities have turned down SAE's attempts to open new chapters, and the fraternity had to close 12 in 18 months over hazing in\n",
    "cidents.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57a3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_ids  = bert_tokenizer(article, return_tensors=\"pt\").input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f237942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_ids = model.generate(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9476022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we need a gpt2 tokenizer for the output word embeddings\n",
    "\n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32dfd03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theresa May's visit to the US was a'very significant'\n",
      "Ninth reign of the 'greatest hope abuse'\n",
      "Theresa was the first to visit the US in the 'Greatest Hope Abuse'\n",
      "Tunisian 'discovery' of the Great Britain's 'lost' imperial possessions.\n",
      "The 'great' British imperialists were 'unjustly persecuted'\n",
      "Aircraft Club 'fast hours deep' and 'deeply felt'\n",
      "Comes as the US is preparing to build a new naval base in the UK.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gpt2_tokenizer.decode(output_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db364ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc9906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08be40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd4b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
